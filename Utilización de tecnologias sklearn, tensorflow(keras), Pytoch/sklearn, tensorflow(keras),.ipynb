{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hP9XRxmgvZDD"
      },
      "source": [
        "##Modelado con Scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-1q7JiUusbD",
        "outputId": "ab5d2526-ce42-4d33-8412-6881993fa571"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       159\n",
            "           1       1.00      1.00      1.00       149\n",
            "\n",
            "    accuracy                           1.00       308\n",
            "   macro avg       1.00      1.00      1.00       308\n",
            "weighted avg       1.00      1.00      1.00       308\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Cargar y preparar datos\n",
        "url = \"https://tauusbmededu-my.sharepoint.com/personal/jeferson_vega231_tau_usbmed_edu_co/_layouts/15/download.aspx?share=EVPG5kJ7esxAhgCt3ftLrGcBT9hZs4KHxOkUwFialqFV-Q\"\n",
        "\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "object_columns = df.select_dtypes(include='object').columns\n",
        "for col in object_columns:\n",
        "    df[col] = df[col].astype(str).str.lower()\n",
        "    df[col] = df[col].astype('category').cat.codes\n",
        "# Dividir en características (X) y etiquetas (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Escalar los datos\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Dividir en conjunto de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Modelo ANN\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100,50), activation='tanh', max_iter=300, random_state=42)\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Predicción y evaluación\n",
        "y_pred = mlp.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfAl98tN890E"
      },
      "source": [
        "## Modelo Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sO3DG-um9Ajw",
        "outputId": "98b473ce-1d2d-4f6b-8406-480d8a33e254"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      1.00      0.68       159\n",
            "           1       0.00      0.00      0.00       149\n",
            "\n",
            "    accuracy                           0.52       308\n",
            "   macro avg       0.26      0.50      0.34       308\n",
            "weighted avg       0.27      0.52      0.35       308\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Cargar datos\n",
        "digits = df\n",
        "X = df.drop(\"target\", axis=1)\n",
        "y = df[\"target\"]\n",
        "\n",
        "# Escalado\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# One-hot encoding de las etiquetas\n",
        "y_cat = to_categorical(y)\n",
        "\n",
        "# División\n",
        "X_train, X_test, y_train_cat, y_test_cat = train_test_split(X, y_cat, test_size=0.3, random_state=42)\n",
        "y_train, y_test = train_test_split(y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Modelo Keras\n",
        "model = Sequential([\n",
        "    Dense(100, activation='relu', input_shape=(X.shape[1],)),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=30, batch_size=32, verbose=0)\n",
        "\n",
        "# Evaluación\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EOXsNSL6UIj"
      },
      "source": [
        "##Modelado con PyTorch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWgiyMDM4Ysf",
        "outputId": "25323d3e-1fa6-4079-b35c-fd17bbdc2870"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/30], Loss: 1.4547\n",
            "Epoch [2/30], Loss: 0.8390\n",
            "Epoch [3/30], Loss: 0.6253\n",
            "Epoch [4/30], Loss: 0.4811\n",
            "Epoch [5/30], Loss: 0.4207\n",
            "Epoch [6/30], Loss: 0.2040\n",
            "Epoch [7/30], Loss: 0.4135\n",
            "Epoch [8/30], Loss: 0.2928\n",
            "Epoch [9/30], Loss: 0.3814\n",
            "Epoch [10/30], Loss: 0.2618\n",
            "Epoch [11/30], Loss: 0.4252\n",
            "Epoch [12/30], Loss: 0.6712\n",
            "Epoch [13/30], Loss: 0.5682\n",
            "Epoch [14/30], Loss: 0.2609\n",
            "Epoch [15/30], Loss: 0.3068\n",
            "Epoch [16/30], Loss: 0.4031\n",
            "Epoch [17/30], Loss: 0.1402\n",
            "Epoch [18/30], Loss: 0.4563\n",
            "Epoch [19/30], Loss: 0.0608\n",
            "Epoch [20/30], Loss: 0.1920\n",
            "Epoch [21/30], Loss: 0.1536\n",
            "Epoch [22/30], Loss: 0.2553\n",
            "Epoch [23/30], Loss: 0.1878\n",
            "Epoch [24/30], Loss: 0.2179\n",
            "Epoch [25/30], Loss: 0.3224\n",
            "Epoch [26/30], Loss: 0.3294\n",
            "Epoch [27/30], Loss: 0.2860\n",
            "Epoch [28/30], Loss: 0.1825\n",
            "Epoch [29/30], Loss: 0.1580\n",
            "Epoch [30/30], Loss: 0.4138\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.86      0.87       159\n",
            "           1       0.85      0.89      0.87       149\n",
            "\n",
            "    accuracy                           0.87       308\n",
            "   macro avg       0.87      0.87      0.87       308\n",
            "weighted avg       0.87      0.87      0.87       308\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "url = \"https://tauusbmededu-my.sharepoint.com/personal/jeferson_vega231_tau_usbmed_edu_co/_layouts/15/download.aspx?share=EVPG5kJ7esxAhgCt3ftLrGcBT9hZs4KHxOkUwFialqFV-Q\"\n",
        "\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "object_columns = df.select_dtypes(include='object').columns\n",
        "for col in object_columns:\n",
        "    df[col] = df[col].astype(str).str.lower()\n",
        "    df[col] = df[col].astype('category').cat.codes\n",
        "# Dividir en características (X) y etiquetas (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Escalado\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Conversión a tensores\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_train_tensor = torch.FloatTensor(X_train)\n",
        "X_test_tensor = torch.FloatTensor(X_test)\n",
        "y_train_tensor = torch.LongTensor(y_train.values)\n",
        "\n",
        "y_test_tensor = torch.LongTensor(y_test.values)\n",
        "\n",
        "# Dataset y DataLoader\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Modelo MLP\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(13, 100)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = Net()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Entrenamiento\n",
        "for epoch in range(30):\n",
        "    for inputs, labels in train_loader:\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "# Mostrar la pérdida por época\n",
        "    print(f\"Epoch [{epoch+1}/30], Loss: {loss.item():.4f}\")\n",
        "# Evaluación\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_test_tensor)\n",
        "    _, y_pred = torch.max(outputs, 1)\n",
        "\n",
        "print(classification_report(y_test_tensor, y_pred))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
